{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b15098fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"API_TOKEN_OPEN_AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc03e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = \"textos_resultados.xlsx\"\n",
    "resultados_file = \"textos_resultados.xlsx\"\n",
    "progreso_file = \"progreso.json\"\n",
    "\n",
    "# Leer el Excel original o el de resultados si ya existe\n",
    "if os.path.exists(resultados_file):\n",
    "    df = pd.read_excel(resultados_file)\n",
    "else:\n",
    "    df = pd.read_excel(excel_file)\n",
    "    # df = df[df['Dataset'] == 'test'].reset_index(drop=True)\n",
    "    df =  df[df['calificacion_tipo_texto'].isna() | (df['calificacion_tipo_texto'] == '')].reset_index(drop=True)\n",
    "    # df[\"calificacion_tipo_texto\"] = None  # Crear columna si no existe\n",
    "\n",
    "# Cargar progreso\n",
    "try:\n",
    "    with open(progreso_file, \"r\") as f:\n",
    "        progreso = json.load(f)\n",
    "        ultimo_indice = progreso.get(\"ultimo_indice\", 0)\n",
    "except FileNotFoundError:\n",
    "    ultimo_indice = 0\n",
    "\n",
    "# Parámetros\n",
    "lote_size = 1\n",
    "\n",
    "pendientes = df[df[\"calificacion_tipo_texto\"].isna()].reset_index().rename(columns={\"index\": \"indice_original\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ea43abc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bcf954ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE 1\n",
      "960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_409763/165555638.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx_original, \"calificacion_tipo_texto\"] = respuestas[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lote 0-1 procesado.\n",
      "RESPONSE 1\n",
      "961\n",
      "Lote 1-2 procesado.\n",
      "RESPONSE 1\n",
      "962\n",
      "Lote 2-3 procesado.\n",
      "RESPONSE 1\n",
      "963\n",
      "Lote 3-4 procesado.\n",
      "RESPONSE 1\n",
      "964\n",
      "Lote 4-5 procesado.\n",
      "RESPONSE 1\n",
      "965\n",
      "Lote 5-6 procesado.\n",
      "RESPONSE 1\n",
      "966\n",
      "Lote 6-7 procesado.\n",
      "RESPONSE 1\n",
      "967\n",
      "Lote 7-8 procesado.\n",
      "RESPONSE 1\n",
      "968\n",
      "Lote 8-9 procesado.\n",
      "RESPONSE 1\n",
      "969\n",
      "Lote 9-10 procesado.\n",
      "RESPONSE 0\n",
      "1250\n",
      "Lote 10-11 procesado.\n",
      "RESPONSE 0\n",
      "1251\n",
      "Lote 11-12 procesado.\n",
      "RESPONSE 0\n",
      "1252\n",
      "Lote 12-13 procesado.\n",
      "RESPONSE 0\n",
      "1253\n",
      "Lote 13-14 procesado.\n",
      "RESPONSE 0\n",
      "1254\n",
      "Lote 14-15 procesado.\n",
      "RESPONSE 0\n",
      "1255\n",
      "Lote 15-16 procesado.\n",
      "RESPONSE 0\n",
      "1256\n",
      "Lote 16-17 procesado.\n",
      "RESPONSE 1\n",
      "1257\n",
      "Lote 17-18 procesado.\n",
      "RESPONSE 0\n",
      "1258\n",
      "Lote 18-19 procesado.\n",
      "RESPONSE 0\n",
      "1259\n",
      "Lote 19-20 procesado.\n",
      "RESPONSE 0\n",
      "1320\n",
      "Lote 20-21 procesado.\n",
      "RESPONSE 0\n",
      "1321\n",
      "Lote 21-22 procesado.\n",
      "RESPONSE 0\n",
      "1322\n",
      "Lote 22-23 procesado.\n",
      "RESPONSE 0\n",
      "1323\n",
      "Lote 23-24 procesado.\n",
      "RESPONSE 0\n",
      "1324\n",
      "Lote 24-25 procesado.\n",
      "RESPONSE 1\n",
      "1325\n",
      "Lote 25-26 procesado.\n",
      "RESPONSE 0\n",
      "1326\n",
      "Lote 26-27 procesado.\n",
      "RESPONSE 0\n",
      "1327\n",
      "Lote 27-28 procesado.\n",
      "RESPONSE 0\n",
      "1328\n",
      "Lote 28-29 procesado.\n",
      "RESPONSE 0\n",
      "1329\n",
      "Lote 29-30 procesado.\n",
      "RESPONSE 0\n",
      "1570\n",
      "Lote 30-31 procesado.\n",
      "RESPONSE 0\n",
      "1571\n",
      "Lote 31-32 procesado.\n",
      "RESPONSE 0\n",
      "1572\n",
      "Lote 32-33 procesado.\n",
      "RESPONSE 0\n",
      "1573\n",
      "Lote 33-34 procesado.\n",
      "RESPONSE 0\n",
      "1574\n",
      "Lote 34-35 procesado.\n",
      "RESPONSE 0\n",
      "1575\n",
      "Lote 35-36 procesado.\n",
      "RESPONSE 0\n",
      "1576\n",
      "Lote 36-37 procesado.\n",
      "RESPONSE 0\n",
      "1577\n",
      "Lote 37-38 procesado.\n",
      "RESPONSE 0\n",
      "1578\n",
      "Lote 38-39 procesado.\n",
      "RESPONSE 0\n",
      "1579\n",
      "Lote 39-40 procesado.\n",
      "RESPONSE 0\n",
      "1590\n",
      "Lote 40-41 procesado.\n",
      "RESPONSE 0\n",
      "1591\n",
      "Lote 41-42 procesado.\n",
      "RESPONSE 0\n",
      "1592\n",
      "Lote 42-43 procesado.\n",
      "RESPONSE 0\n",
      "1593\n",
      "Lote 43-44 procesado.\n",
      "RESPONSE 0\n",
      "1594\n",
      "Lote 44-45 procesado.\n",
      "RESPONSE 0\n",
      "1595\n",
      "Lote 45-46 procesado.\n",
      "RESPONSE 0\n",
      "1596\n",
      "Lote 46-47 procesado.\n",
      "RESPONSE 0\n",
      "1597\n",
      "Lote 47-48 procesado.\n",
      "RESPONSE 0\n",
      "1598\n",
      "Lote 48-49 procesado.\n",
      "RESPONSE 0\n",
      "1599\n",
      "Lote 49-50 procesado.\n",
      "RESPONSE 0\n",
      "1700\n",
      "Lote 50-51 procesado.\n",
      "RESPONSE 0\n",
      "1701\n",
      "Lote 51-52 procesado.\n",
      "RESPONSE 0\n",
      "1702\n",
      "Lote 52-53 procesado.\n",
      "RESPONSE 0\n",
      "1703\n",
      "Lote 53-54 procesado.\n",
      "RESPONSE 0\n",
      "1704\n",
      "Lote 54-55 procesado.\n",
      "RESPONSE 0\n",
      "1705\n",
      "Lote 55-56 procesado.\n",
      "RESPONSE 0\n",
      "1706\n",
      "Lote 56-57 procesado.\n",
      "RESPONSE 0\n",
      "1707\n",
      "Lote 57-58 procesado.\n",
      "RESPONSE 1\n",
      "1708\n",
      "Lote 58-59 procesado.\n",
      "RESPONSE 0\n",
      "1709\n",
      "Lote 59-60 procesado.\n"
     ]
    }
   ],
   "source": [
    "for start in range(0, len(pendientes), lote_size):\n",
    "    end = min(start + lote_size, len(pendientes))\n",
    "    lote = pendientes.iloc[start:end]\n",
    "\n",
    "\n",
    "    textos = lote[\"Texto\"].tolist()\n",
    "\n",
    "    # Simulación de respuesta (reemplaza por llamada real a la API)\n",
    "    prompt = f\"\"\"\n",
    "      Tu tarea es clasificar si los textos son de humor o gracia o no\n",
    "      \n",
    "      Debes brindar la respuesta sin texto introductorio asignando asignando 1 si es de humor o gracia o 0 de lo contrario, seperado por comas\n",
    "\n",
    "{chr(10).join(['Texto: ' + i for i in textos])}\n",
    "      \"\"\"\n",
    "    # print(prompt)\n",
    "    # respuestas = [f\"Calificación simulada para texto {i+start}\" for i in range(len(textos))]\n",
    "\n",
    "    # Guardar calificaciones\n",
    "    # print(respuestas)\n",
    "    # print(start,end)\n",
    "    # print(df.loc[start:end-1, \"calificacion_tipo_texto\"] )\n",
    "    # print(prompt)\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o-mini\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt}\n",
    "      ]\n",
    "      )\n",
    "    response = completion.choices[0].message.content\n",
    "    print(\"RESPONSE\",response)\n",
    "    if len(response.split(',')) == len(textos):\n",
    "      respuestas = response.split(',')\n",
    "      \n",
    "      for i, idx_original in enumerate(lote[\"indice_original\"]):\n",
    "        print(f\"{idx_original}\")\n",
    "        df.at[idx_original, \"calificacion_tipo_texto\"] = respuestas[i]\n",
    "    else:\n",
    "       print(\"####ERROR\")\n",
    "       pass\n",
    "    # Guardar resultados\n",
    "    df.to_excel(resultados_file, index=False)\n",
    "\n",
    "    # Guardar progreso\n",
    "    with open(progreso_file, \"w\") as f:\n",
    "        json.dump({\"ultimo_indice\": end}, f)\n",
    "\n",
    "    print(f\"Lote {start}-{end} procesado.\")\n",
    "    time.sleep(1)  # espera opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f61543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c234df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
